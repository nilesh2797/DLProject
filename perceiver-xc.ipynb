{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "8c3c640c",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-11-22T22:43:56.922220Z",
     "start_time": "2021-11-22T22:43:56.582508Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>.container { width:100% !important; }</style>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from IPython.core.display import display, HTML\n",
    "display(HTML(\"<style>.container { width:100% !important; }</style>\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "ca772133",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-11-22T22:43:58.337763Z",
     "start_time": "2021-11-22T22:43:58.334273Z"
    }
   },
   "outputs": [],
   "source": [
    "# downlaod deepmind's pretrained language model\n",
    "# !wget -O deepmind_assets/language_perceiver_io_bytes.pickle https://storage.googleapis.com/perceiver_io/language_perceiver_io_bytes.pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "b0b3fcf9",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-11-22T22:43:58.594892Z",
     "start_time": "2021-11-22T22:43:58.547251Z"
    }
   },
   "outputs": [],
   "source": [
    "command = \"--dataset EURLex-4K\"\n",
    "\n",
    "import argparse\n",
    "parser = argparse.ArgumentParser()\n",
    "parser.add_argument('--project', default='PerceiverIO')\n",
    "parser.add_argument('--dataset', default='EURLex-4K')\n",
    "parser.add_argument('--device', type=str, default='cuda:0')\n",
    "\n",
    "args = parser.parse_args(command.split())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "a7cddcb9",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-11-22T22:43:58.755027Z",
     "start_time": "2021-11-22T22:43:58.747719Z"
    }
   },
   "outputs": [],
   "source": [
    "args.expname = args.project\n",
    "args.maxlen = 2048\n",
    "args.vocab_size = 262\n",
    "args.embed_dim = 768\n",
    "args.num_latents = 256\n",
    "\n",
    "args.n_epochs = 10\n",
    "args.xc_lr = 1e-2\n",
    "args.enc_lr = 2e-5\n",
    "args.bsz = 32\n",
    "args.dropout = 0.4\n",
    "args.warmup = 0.1\n",
    "args.loss_with_logits = True\n",
    "args.amp = False\n",
    "args.eval_interval = 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "aa32b428",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-11-22T22:44:42.420172Z",
     "start_time": "2021-11-22T22:43:59.081710Z"
    }
   },
   "outputs": [],
   "source": [
    "from perceiver_io.perceiver_lm import PerceiverLM\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import transformers\n",
    "\n",
    "from deepmind_assets import bytes_tokenizer\n",
    "import numpy as np\n",
    "from tqdm.notebook import tqdm\n",
    "import scipy.sparse as sp\n",
    "# The tokenizer is just UTF-8 encoding (with an offset)\n",
    "tokenizer = bytes_tokenizer.BytesTokenizer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "bd29aa79",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-11-22T22:45:08.687463Z",
     "start_time": "2021-11-22T22:44:42.424189Z"
    }
   },
   "outputs": [],
   "source": [
    "encoder = PerceiverLM(vocab_size=args.vocab_size, \n",
    "                    max_seq_len=args.maxlen, \n",
    "                    embedding_dim=args.embed_dim, \n",
    "                    num_latents=args.num_latents, \n",
    "                    latent_dim=1280, \n",
    "                    qk_out_dim=256, \n",
    "                    num_self_attn_per_block=26, \n",
    "                    lm=False)\n",
    "\n",
    "encoder.load_pretrained(\"deepmind_assets/language_perceiver_io_bytes.pickle\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "afc4febb",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-11-22T21:54:59.915190Z",
     "start_time": "2021-11-22T21:54:59.915175Z"
    }
   },
   "outputs": [],
   "source": [
    "input_str = \"This is an incomplete sentence where some words are missing.\"\n",
    "input_tokens = tokenizer.to_int(input_str)\n",
    "\n",
    "# Mask \" missing.\". Note that the model performs much better if the masked chunk\n",
    "# starts with a space.\n",
    "input_tokens[51:60] = tokenizer.mask_token\n",
    "print(\"Tokenized string without masked bytes:\")\n",
    "print(tokenizer.to_string(input_tokens))\n",
    "\n",
    "#@title Pad and reshape inputs\n",
    "inputs = input_tokens[None]\n",
    "input_mask = np.ones_like(inputs)\n",
    "\n",
    "def pad(max_sequence_length: int, inputs, input_mask):\n",
    "    input_len = inputs.shape[1]\n",
    "    assert input_len <= max_sequence_length\n",
    "    pad_len = max_sequence_length - input_len\n",
    "    padded_inputs = np.pad(\n",
    "      inputs,\n",
    "      pad_width=((0, 0), (0, pad_len)),\n",
    "      constant_values=tokenizer.pad_token)\n",
    "    padded_mask = np.pad(\n",
    "      input_mask,\n",
    "      pad_width=((0, 0), (0, pad_len)),\n",
    "      constant_values=0)\n",
    "    return padded_inputs, padded_mask\n",
    "\n",
    "inputs, input_mask = pad(args.maxlen, inputs, input_mask)\n",
    "\n",
    "encoder.eval()\n",
    "mask = torch.tensor(input_mask)\n",
    "input_ids = torch.tensor(inputs)\n",
    "out = encoder.forward(input_ids, mask)\n",
    "\n",
    "embs = out * mask.unsqueeze(-1) / mask.sum(dim=-1)\n",
    "\n",
    "logits = torch.matmul(out, encoder.token_embedding.weight.T) + encoder.decoder_token_bias\n",
    "masked_tokens_predictions = logits[0, 51:60].argmax(dim=-1)\n",
    "print(\"Greedy predictions:\")\n",
    "print(masked_tokens_predictions)\n",
    "print()\n",
    "print(\"Predicted string:\")\n",
    "print(tokenizer.to_string(masked_tokens_predictions.cpu().detach().numpy()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "f46123c3",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-11-22T22:45:11.509724Z",
     "start_time": "2021-11-22T22:45:08.689975Z"
    }
   },
   "outputs": [],
   "source": [
    "from utils import csr_to_pad_tensor, ToD, read_sparse_mat\n",
    "from torch.nn.utils.rnn import pad_sequence\n",
    "\n",
    "class XMLDataset(torch.utils.data.Dataset):\n",
    "    def __init__(self, inputs, labels, tokenizer, maxlen):\n",
    "        self.maxlen = maxlen\n",
    "        self.input_ids = pad_sequence([torch.LongTensor(tokenizer.to_int(x)[:maxlen]) for x in inputs], batch_first=True, padding_value=0)\n",
    "        self.input_mask = (self.input_ids != 0).long()\n",
    "        self.labels = labels\n",
    "            \n",
    "    def __getitem__(self, index):\n",
    "        return index\n",
    "    \n",
    "    def get_fts(self, indices, source='point'):\n",
    "        input_mask = self.input_mask[indices]\n",
    "        max_batch_seq_len = input_mask.sum(dim=-1).max()\n",
    "        return {'input_ids': self.input_ids[indices, :max_batch_seq_len], 'input_mask': input_mask[:, :max_batch_seq_len]}\n",
    "   \n",
    "    def __len__(self):\n",
    "        return self.labels.shape[0]\n",
    "    \n",
    "class XMLCollator():\n",
    "    def __init__(self, dataset):\n",
    "        self.numy = dataset.labels.shape[1]\n",
    "        self.dataset = dataset\n",
    "    \n",
    "    def __call__(self, batch):\n",
    "        ids = torch.LongTensor(batch)\n",
    "        batch_data = {'batch_size': torch.LongTensor([len(batch)]),\n",
    "                      'numy': torch.LongTensor([self.numy]),\n",
    "                      'y': csr_to_pad_tensor(self.dataset.labels[ids], self.numy),\n",
    "                      'ids': ids,\n",
    "                      'xfts': self.dataset.get_fts(ids)\n",
    "                     }\n",
    "                \n",
    "        return batch_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "b1ca9b2e",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-11-22T22:45:12.983701Z",
     "start_time": "2021-11-22T22:45:11.511851Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "15449it [00:00, 103796.22it/s]\n",
      "3865it [00:00, 124525.55it/s]\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'xc_metrics' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_182613/4162644157.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mtrn_X_Y\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mread_sparse_mat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf'{DATA_DIR}/trn_X_Y.txt'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0muse_xclib\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0mtst_X_Y\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mread_sparse_mat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf'{DATA_DIR}/tst_X_Y.txt'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0muse_xclib\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 7\u001b[0;31m \u001b[0minv_prop\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mxc_metrics\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcompute_inv_propesity\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrn_X_Y\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0.55\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1.5\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      8\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnumy\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrn_X_Y\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'xc_metrics' is not defined"
     ]
    }
   ],
   "source": [
    "DATA_DIR = 'Datasets/EURLex-4K'\n",
    "\n",
    "trnX = [x.strip() for x in open(f'{DATA_DIR}/raw/trn_X.txt').readlines()]\n",
    "tstX = [x.strip() for x in open(f'{DATA_DIR}/raw/tst_X.txt').readlines()]\n",
    "trn_X_Y = read_sparse_mat(f'{DATA_DIR}/trn_X_Y.txt', use_xclib=False)\n",
    "tst_X_Y = read_sparse_mat(f'{DATA_DIR}/tst_X_Y.txt', use_xclib=False)\n",
    "inv_prop = xc_metrics.compute_inv_propesity(trn_X_Y, 0.55, 1.5)\n",
    "\n",
    "args.numy = trn_X_Y.shape[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "9a4e48f5",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-11-22T21:13:04.730934Z",
     "start_time": "2021-11-22T21:13:03.633637Z"
    }
   },
   "outputs": [],
   "source": [
    "trn_dataset = XMLDataset(trnX, trn_X_Y, tokenizer, args.maxlen)\n",
    "tst_dataset = XMLDataset(tstX, tst_X_Y, tokenizer, args.maxlen)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "3f3e4cab",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-11-22T21:13:05.870920Z",
     "start_time": "2021-11-22T21:13:05.863415Z"
    }
   },
   "outputs": [],
   "source": [
    "trn_loader = torch.utils.data.DataLoader(\n",
    "    trn_dataset,\n",
    "    batch_size=4,\n",
    "    num_workers=2,\n",
    "    collate_fn=XMLCollator(trn_dataset),\n",
    "    shuffle=True,\n",
    "    pin_memory=True)\n",
    "\n",
    "tst_loader = torch.utils.data.DataLoader(\n",
    "    tst_dataset,\n",
    "    batch_size=args.bsz,\n",
    "    num_workers=2,\n",
    "    collate_fn=XMLCollator(tst_dataset),\n",
    "    shuffle=False,\n",
    "    pin_memory=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "aefffc22",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-11-22T21:28:34.538343Z",
     "start_time": "2021-11-22T21:28:34.523616Z"
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "class Net(nn.Module):\n",
    "    def __init__(self, encoder, args):\n",
    "        super().__init__()\n",
    "        self.encoder = encoder\n",
    "        self.numy = args.numy\n",
    "        self.dropout = nn.Dropout(args.dropout)\n",
    "        self.w = nn.Linear(args.embed_dim, args.numy)\n",
    "    \n",
    "    def forward(self, b):\n",
    "        embs = self.encoder(b['xfts']['input_ids'], b['xfts']['input_mask'])\n",
    "        mask = b['xfts']['input_mask']\n",
    "        embs = embs * mask.unsqueeze(-1) / mask.sum(dim=-1).reshape(-1, 1, 1)\n",
    "        embs = embs.sum(dim=1)\n",
    "        out = self.w(self.dropout(embs))\n",
    "        return out\n",
    "    \n",
    "    def predict(self, tst_loader, K=100):\n",
    "        tst_X_Y = tst_loader.dataset.labels\n",
    "        data = np.zeros((tst_X_Y.shape[0], K))\n",
    "        inds = np.zeros((tst_X_Y.shape[0], K)).astype(np.int32)\n",
    "        indptr = np.arange(0, tst_X_Y.shape[0]*K+1, K)\n",
    "        self.eval()\n",
    "\n",
    "        with torch.no_grad():\n",
    "            for b in tqdm(tst_loader, leave=True, desc='Evaluating'):\n",
    "                b = ToD(b, self.get_device())\n",
    "                out = self(b)\n",
    "                top_data, top_inds = torch.topk(out, K)\n",
    "                data[b['ids'].cpu()] = top_data.detach().cpu().numpy()\n",
    "                inds[b['ids'].cpu()] = top_inds.detach().cpu().numpy()\n",
    "                del top_data, top_inds, b, out\n",
    "\n",
    "        torch.cuda.empty_cache()\n",
    "        score_mat = sp.csr_matrix((data.ravel(), inds.ravel(), indptr), tst_X_Y.shape)\n",
    "        \n",
    "        return score_mat\n",
    "    \n",
    "class OvABCELoss(nn.Module):\n",
    "    def __init__(self, args, reduction='mean'):\n",
    "        super(OvABCELoss, self).__init__()\n",
    "        if args.loss_with_logits:\n",
    "            self.criterion = torch.nn.BCEWithLogitsLoss(reduction=reduction)\n",
    "        else:\n",
    "            self.criterion = torch.nn.BCELoss(reduction=reduction)\n",
    "\n",
    "    def forward(self, model, b):\n",
    "        out = model(b)\n",
    "        targets = torch.zeros((out.shape[0], out.shape[1]+1), device=out.device).scatter_(1, b['y']['inds'], 1)[:, :-1]\n",
    "        loss = self.criterion(out, targets)\n",
    "        return loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "f6b36845",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-11-22T21:22:11.688150Z",
     "start_time": "2021-11-22T21:22:11.641518Z"
    }
   },
   "outputs": [],
   "source": [
    "net = Net(encoder, args)\n",
    "loss = OvABCELoss(args)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "820f5a54",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-11-22T21:31:29.284314Z",
     "start_time": "2021-11-22T21:31:29.263640Z"
    }
   },
   "outputs": [],
   "source": [
    "optim_wrap = {\n",
    "    'xc' : {'class': torch.optim.Adam, 'params': [], 'args': {'lr': args.xc_lr}},\n",
    "    'enc': {'class': transformers.optimization.AdamW, 'params': [], \n",
    "            'args': {'lr': args.enc_lr, 'eps': 1e-06, 'weight_decay': 0.01}}\n",
    "    }\n",
    "\n",
    "for n,p in net.named_parameters():\n",
    "    if n[:8] == 'encoder.': optim_wrap['enc']['params'].append(p)\n",
    "    else: optim_wrap['xc']['params'].append(p)\n",
    "        \n",
    "optims = []\n",
    "for k, v in optim_wrap.items():\n",
    "    if len(v['params']) > 0: optims.append(v['class'](v['params'], **v['args']))\n",
    "        \n",
    "\n",
    "total_steps = len(trn_loader)*args.n_epochs\n",
    "schedulers = [transformers.get_linear_schedule_with_warmup(optim, num_warmup_steps=int(args.warmup*total_steps), num_training_steps=total_steps) for optim in optims]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "b84958ae",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-11-22T21:22:12.016671Z",
     "start_time": "2021-11-22T21:22:12.008128Z"
    }
   },
   "outputs": [],
   "source": [
    "net.eval();"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "79193c72",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-11-22T21:13:10.974978Z",
     "start_time": "2021-11-22T21:13:10.800372Z"
    }
   },
   "outputs": [],
   "source": [
    "best_ndcg = -100\n",
    "for epoch in range(args.n_epochs):\n",
    "    net.train()\n",
    "    cum_loss = 0; ctr = 0\n",
    "    t = tqdm(trn_loader, desc='Epoch: 0, Loss: 0.0', leave=True)\n",
    "          \n",
    "    for b in t:        \n",
    "        for optim in optims: optim.zero_grad()\n",
    "        b = net.ToD(b)\n",
    "        with torch.cuda.amp.autocast(enabled=args.amp):\n",
    "            loss = criterion(net, b)\n",
    "        loss.backward()\n",
    "        for optim in optims: optim.step()\n",
    "        for sch in schedulers: sch.step()\n",
    "        cum_loss += loss.item()\n",
    "        ctr += 1\n",
    "        t.set_description('Epoch: %d/%d, Loss: %.4E'%(epoch, args.n_epochs, (cum_loss/ctr)), refresh=True)\n",
    "    \n",
    "    print(f'mean loss after epoch {epoch}/{args.n_epochs}: {\"%.4E\"%(cum_loss/ctr)}', flush=True)\n",
    "    if epoch%args.eval_interval == 0 or epoch == (args.n_epochs-1):\n",
    "        score_mat = net.predict(tst_loader)\n",
    "        metrics = XCMetrics(score_mat, tst_X_Y, inv_prop, method=args.expname, disp=True)\n",
    "\n",
    "        if metrics.loc[args.expname]['nDCG@5'] > best_ndcg:\n",
    "            best_ndcg = metrics.loc[args.expname]['nDCG@5']\n",
    "            print(_c(f'Found new best model with nDCG@5: {\"%.2f\"%best_ndcg}\\n', attr='blue'))\n",
    "            sp.save_npz(f'{OUT_DIR}/score_mat.npz', score_mat)\n",
    "            metrics.to_csv(f'{OUT_DIR}/metrics.tsv', sep='\\t')\n",
    "            torch.save(net.state_dict(), f'{OUT_DIR}/model.pt')\n",
    "    sys.stdout.flush()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "109b182b",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-11-22T21:22:25.562227Z",
     "start_time": "2021-11-22T21:22:25.118579Z"
    },
    "scrolled": true
   },
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "[enforce fail at CPUAllocator.cpp:68] . DefaultCPUAllocator: can't allocate memory: you tried to allocate 67108864 bytes. Error code 12 (Cannot allocate memory)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_149796/436112519.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mout\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnet\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mb\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/work2/08343/nilesh/maverick2/anaconda3/envs/xc/lib/python3.7/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1100\u001b[0m         if not (self._backward_hooks or self._forward_hooks or self._forward_pre_hooks or _global_backward_hooks\n\u001b[1;32m   1101\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1102\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1103\u001b[0m         \u001b[0;31m# Do not call functions when jit is used\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1104\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/tmp/ipykernel_149796/3732504911.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, b)\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mb\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 10\u001b[0;31m         \u001b[0membs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mencoder\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mb\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'xfts'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'input_ids'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mb\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'xfts'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'input_mask'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     11\u001b[0m         \u001b[0mmask\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mb\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'xfts'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'input_mask'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     12\u001b[0m         \u001b[0membs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0membs\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mmask\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0munsqueeze\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m/\u001b[0m \u001b[0mmask\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msum\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdim\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreshape\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/work2/08343/nilesh/maverick2/anaconda3/envs/xc/lib/python3.7/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1100\u001b[0m         if not (self._backward_hooks or self._forward_hooks or self._forward_pre_hooks or _global_backward_hooks\n\u001b[1;32m   1101\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1102\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1103\u001b[0m         \u001b[0;31m# Do not call functions when jit is used\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1104\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/work2/08343/nilesh/maverick2/courses/DL/DLProject/perceiver_io/perceiver_lm.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, inputs, mask)\u001b[0m\n\u001b[1;32m     80\u001b[0m             \u001b[0mquery\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mquery_embeddings\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     81\u001b[0m             \u001b[0minput_mask\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmask\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 82\u001b[0;31m             \u001b[0mquery_mask\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmask\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     83\u001b[0m         )\n\u001b[1;32m     84\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlm\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/work2/08343/nilesh/maverick2/anaconda3/envs/xc/lib/python3.7/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1100\u001b[0m         if not (self._backward_hooks or self._forward_hooks or self._forward_pre_hooks or _global_backward_hooks\n\u001b[1;32m   1101\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1102\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1103\u001b[0m         \u001b[0;31m# Do not call functions when jit is used\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1104\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/work2/08343/nilesh/maverick2/courses/DL/DLProject/perceiver_io/perceiver.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, inputs, query, input_mask, query_mask)\u001b[0m\n\u001b[1;32m     45\u001b[0m             \u001b[0mOutput\u001b[0m \u001b[0mtensor\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     46\u001b[0m         \"\"\"\n\u001b[0;32m---> 47\u001b[0;31m         \u001b[0mlatents\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mencoder\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkv_mask\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minput_mask\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     48\u001b[0m         outputs = self.decoder(\n\u001b[1;32m     49\u001b[0m             \u001b[0mquery\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mquery\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/work2/08343/nilesh/maverick2/anaconda3/envs/xc/lib/python3.7/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1100\u001b[0m         if not (self._backward_hooks or self._forward_hooks or self._forward_pre_hooks or _global_backward_hooks\n\u001b[1;32m   1101\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1102\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1103\u001b[0m         \u001b[0;31m# Do not call functions when jit is used\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1104\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/work2/08343/nilesh/maverick2/courses/DL/DLProject/perceiver_io/encoder.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, x, kv_mask)\u001b[0m\n\u001b[1;32m    103\u001b[0m             \u001b[0minputs_kv\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    104\u001b[0m             \u001b[0minputs_q\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlatents\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrepeat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch_size\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 105\u001b[0;31m             \u001b[0mattention_mask\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mkv_mask\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    106\u001b[0m         )\n\u001b[1;32m    107\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0m_\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnum_blocks\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/work2/08343/nilesh/maverick2/anaconda3/envs/xc/lib/python3.7/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1100\u001b[0m         if not (self._backward_hooks or self._forward_hooks or self._forward_pre_hooks or _global_backward_hooks\n\u001b[1;32m   1101\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1102\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1103\u001b[0m         \u001b[0;31m# Do not call functions when jit is used\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1104\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/work2/08343/nilesh/maverick2/courses/DL/DLProject/perceiver_io/attention.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, inputs_kv, inputs_q, attention_mask)\u001b[0m\n\u001b[1;32m    242\u001b[0m             \u001b[0minputs_kv\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mkv_layer_norm\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs_kv\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    243\u001b[0m             \u001b[0minputs_q\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mq_layer_norm\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs_q\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 244\u001b[0;31m             \u001b[0mattention_mask\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mattention_mask\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    245\u001b[0m         )\n\u001b[1;32m    246\u001b[0m         \u001b[0mattention\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdropout\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mattention\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/work2/08343/nilesh/maverick2/anaconda3/envs/xc/lib/python3.7/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1100\u001b[0m         if not (self._backward_hooks or self._forward_hooks or self._forward_pre_hooks or _global_backward_hooks\n\u001b[1;32m   1101\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1102\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1103\u001b[0m         \u001b[0;31m# Do not call functions when jit is used\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1104\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/work2/08343/nilesh/maverick2/courses/DL/DLProject/perceiver_io/attention.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, inputs_kv, inputs_q, attention_mask)\u001b[0m\n\u001b[1;32m     72\u001b[0m         \u001b[0mq\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mrearrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mq\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'b s (n h) -> b n s h'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mh\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mqk_head_dim\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     73\u001b[0m         \u001b[0mv\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mrearrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mv\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'b s (n h) -> b n s h'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mh\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mv_head_dim\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 74\u001b[0;31m         \u001b[0mattention\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mq\u001b[0m \u001b[0;34m@\u001b[0m \u001b[0mk\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtranspose\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mscale\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     75\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mattention_mask\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     76\u001b[0m             \u001b[0mmin_value\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfinfo\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mattention\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmin\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mRuntimeError\u001b[0m: [enforce fail at CPUAllocator.cpp:68] . DefaultCPUAllocator: can't allocate memory: you tried to allocate 67108864 bytes. Error code 12 (Cannot allocate memory)"
     ]
    }
   ],
   "source": [
    "out = net(b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "d8536a83",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-11-18T21:38:58.932235Z",
     "start_time": "2021-11-18T21:38:58.913729Z"
    }
   },
   "outputs": [],
   "source": [
    "num_params = 0\n",
    "for p in model.parameters():\n",
    "    num_params += np.prod(p.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "49493169",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-11-18T21:39:01.511003Z",
     "start_time": "2021-11-18T21:39:01.504628Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "201108230"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "num_params"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:vit]",
   "language": "python",
   "name": "conda-env-vit-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
