{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "8c3c640c",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-11-29T20:45:32.769527Z",
     "start_time": "2021-11-29T20:45:32.757064Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>.container { width:100% !important; }</style>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from IPython.core.display import display, HTML\n",
    "display(HTML(\"<style>.container { width:100% !important; }</style>\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "ca772133",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-11-29T20:45:34.291517Z",
     "start_time": "2021-11-29T20:45:34.289390Z"
    }
   },
   "outputs": [],
   "source": [
    "# downlaod deepmind's pretrained language model\n",
    "# !wget -O deepmind_assets/language_perceiver_io_bytes.pickle https://storage.googleapis.com/perceiver_io/language_perceiver_io_bytes.pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "aa32b428",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-11-29T20:45:37.590455Z",
     "start_time": "2021-11-29T20:45:34.626850Z"
    }
   },
   "outputs": [],
   "source": [
    "from perceiver_io.perceiver_lm import PerceiverLM\n",
    "\n",
    "import os, sys\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import transformers\n",
    "\n",
    "from deepmind_assets import bytes_tokenizer\n",
    "import numpy as np\n",
    "import scipy.sparse as sp\n",
    "from tqdm.notebook import tqdm\n",
    "import scipy.sparse as sp\n",
    "import xclib.evaluation.xc_metrics as xc_metrics\n",
    "from utils import csr_to_pad_tensor, ToD, read_sparse_mat, XCMetrics, _c\n",
    "from torch.nn.utils.rnn import pad_sequence\n",
    "\n",
    "# The tokenizer is just UTF-8 encoding (with an offset)\n",
    "tokenizer = bytes_tokenizer.BytesTokenizer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b0b3fcf9",
   "metadata": {
    "ExecuteTime": {
     "start_time": "2021-11-29T20:45:16.601Z"
    }
   },
   "outputs": [],
   "source": [
    "command = \"--dataset EURLex-4K\"\n",
    "\n",
    "import argparse\n",
    "parser = argparse.ArgumentParser()\n",
    "parser.add_argument('--project', default='PerceiverIO')\n",
    "parser.add_argument('--dataset', default='EURLex-4K')\n",
    "parser.add_argument('--device', type=str, default='cuda:0')\n",
    "\n",
    "args = parser.parse_args(command.split())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "a7cddcb9",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-11-22T22:43:58.755027Z",
     "start_time": "2021-11-22T22:43:58.747719Z"
    }
   },
   "outputs": [],
   "source": [
    "args.expname = args.project\n",
    "args.maxlen = 2048\n",
    "args.vocab_size = 262\n",
    "args.embed_dim = 768\n",
    "args.num_latents = 256\n",
    "\n",
    "args.n_epochs = 25\n",
    "args.xc_lr = 1e-3\n",
    "args.enc_lr = 1e-4\n",
    "args.bsz = 32\n",
    "args.dropout = 0.5\n",
    "args.warmup = 0.1\n",
    "args.loss_with_logits = True\n",
    "args.amp = True\n",
    "args.eval_interval = 2\n",
    "\n",
    "args.per_label_task = True\n",
    "args.per_token_decoder = False\n",
    "\n",
    "OUT_DIR = f'{args.project}/{args.dataset}'\n",
    "os.makedirs(OUT_DIR, exist_ok=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "b1ca9b2e",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-11-22T22:45:12.983701Z",
     "start_time": "2021-11-22T22:45:11.511851Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "15449it [00:00, 181291.64it/s]\n",
      "3865it [00:00, 188084.29it/s]\n"
     ]
    }
   ],
   "source": [
    "DATA_DIR = 'Datasets/EURLex-4K'\n",
    "\n",
    "trnX = [x.strip() for x in open(f'{DATA_DIR}/raw/trn_X.txt').readlines()]\n",
    "tstX = [x.strip() for x in open(f'{DATA_DIR}/raw/tst_X.txt').readlines()]\n",
    "trn_X_Y = read_sparse_mat(f'{DATA_DIR}/trn_X_Y.txt', use_xclib=False)\n",
    "tst_X_Y = read_sparse_mat(f'{DATA_DIR}/tst_X_Y.txt', use_xclib=False)\n",
    "inv_prop = xc_metrics.compute_inv_propesity(trn_X_Y, 0.55, 1.5)\n",
    "\n",
    "args.numy = trn_X_Y.shape[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "bd29aa79",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-11-22T22:45:08.687463Z",
     "start_time": "2021-11-22T22:44:42.424189Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_IncompatibleKeys(missing_keys=['query_task_embedding.weight'], unexpected_keys=[])\n"
     ]
    }
   ],
   "source": [
    "encoder = PerceiverLM(vocab_size=args.vocab_size, \n",
    "                      max_seq_len=args.maxlen, \n",
    "                      embedding_dim=args.embed_dim, \n",
    "                      num_latents=args.num_latents, \n",
    "                      latent_dim=1280, \n",
    "                      qk_out_dim=256, \n",
    "                      dropout=0,\n",
    "                      num_self_attn_per_block=26, \n",
    "                      per_token_decoder=args.per_token_decoder, \n",
    "                      num_query_tasks=args.numy if args.per_label_task else 1)\n",
    "\n",
    "encoder.load_pretrained(\"deepmind_assets/language_perceiver_io_bytes.pickle\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "afc4febb",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-11-22T21:54:59.915190Z",
     "start_time": "2021-11-22T21:54:59.915175Z"
    }
   },
   "outputs": [],
   "source": [
    "## Sanity check for encoder with per_token_decoder=True\n",
    "\n",
    "# input_str = \"This is an incomplete sentence where some words are missing.\"\n",
    "# input_tokens = tokenizer.to_int(input_str)\n",
    "\n",
    "# # Mask \" missing.\". Note that the model performs much better if the masked chunk\n",
    "# # starts with a space.\n",
    "# input_tokens[51:60] = tokenizer.mask_token\n",
    "# print(\"Tokenized string without masked bytes:\")\n",
    "# print(tokenizer.to_string(input_tokens))\n",
    "\n",
    "# #@title Pad and reshape inputs\n",
    "# inputs = input_tokens[None]\n",
    "# input_mask = np.ones_like(inputs)\n",
    "\n",
    "# def pad(max_sequence_length: int, inputs, input_mask):\n",
    "#     input_len = inputs.shape[1]\n",
    "#     assert input_len <= max_sequence_length\n",
    "#     pad_len = max_sequence_length - input_len\n",
    "#     padded_inputs = np.pad(\n",
    "#       inputs,\n",
    "#       pad_width=((0, 0), (0, pad_len)),\n",
    "#       constant_values=tokenizer.pad_token)\n",
    "#     padded_mask = np.pad(\n",
    "#       input_mask,\n",
    "#       pad_width=((0, 0), (0, pad_len)),\n",
    "#       constant_values=0)\n",
    "#     return padded_inputs, padded_mask\n",
    "\n",
    "# inputs, input_mask = pad(args.maxlen, inputs, input_mask)\n",
    "\n",
    "# encoder.eval()\n",
    "# mask = torch.tensor(input_mask)\n",
    "# input_ids = torch.tensor(inputs)\n",
    "# out = encoder.forward(input_ids, mask)\n",
    "\n",
    "# embs = out * mask.unsqueeze(-1) / mask.sum(dim=-1)\n",
    "\n",
    "# logits = torch.matmul(out, encoder.token_embedding.weight.T) + encoder.decoder_token_bias\n",
    "# masked_tokens_predictions = logits[0, 51:60].argmax(dim=-1)\n",
    "# print(\"Greedy predictions:\")\n",
    "# print(masked_tokens_predictions)\n",
    "# print()\n",
    "# print(\"Predicted string:\")\n",
    "# print(tokenizer.to_string(masked_tokens_predictions.cpu().detach().numpy()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "4cc9206e",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-11-22T22:45:11.509724Z",
     "start_time": "2021-11-22T22:45:08.689975Z"
    }
   },
   "outputs": [],
   "source": [
    "class XMLDataset(torch.utils.data.Dataset):\n",
    "    def __init__(self, inputs, labels, tokenizer, maxlen):\n",
    "        self.maxlen = maxlen\n",
    "        self.input_ids = pad_sequence([torch.LongTensor(tokenizer.to_int(x)[:maxlen]) for x in inputs], batch_first=True, padding_value=0)\n",
    "        self.input_mask = (self.input_ids != 0).long()\n",
    "        self.labels = labels\n",
    "            \n",
    "    def __getitem__(self, index):\n",
    "        return index\n",
    "    \n",
    "    def get_fts(self, indices, source='point'):\n",
    "        input_mask = self.input_mask[indices]\n",
    "        max_batch_seq_len = input_mask.sum(dim=-1).max()\n",
    "        return {'input_ids': self.input_ids[indices, :max_batch_seq_len], 'input_mask': input_mask[:, :max_batch_seq_len]}\n",
    "   \n",
    "    def __len__(self):\n",
    "        return self.labels.shape[0]\n",
    "    \n",
    "class XMLCollator():\n",
    "    def __init__(self, dataset):\n",
    "        self.numy = dataset.labels.shape[1]\n",
    "        self.dataset = dataset\n",
    "    \n",
    "    def __call__(self, batch):\n",
    "        ids = torch.LongTensor(batch)\n",
    "        batch_data = {'batch_size': torch.LongTensor([len(batch)]),\n",
    "                      'numy': torch.LongTensor([self.numy]),\n",
    "                      'y': csr_to_pad_tensor(self.dataset.labels[ids], self.numy),\n",
    "                      'ids': ids,\n",
    "                      'xfts': self.dataset.get_fts(ids)\n",
    "                     }\n",
    "                \n",
    "        return batch_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "f46123c3",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-11-22T22:45:11.509724Z",
     "start_time": "2021-11-22T22:45:08.689975Z"
    }
   },
   "outputs": [],
   "source": [
    "trn_dataset = XMLDataset(trnX, trn_X_Y, tokenizer, args.maxlen)\n",
    "tst_dataset = XMLDataset(tstX, tst_X_Y, tokenizer, args.maxlen)\n",
    "\n",
    "trn_loader = torch.utils.data.DataLoader(\n",
    "    trn_dataset,\n",
    "    batch_size=args.bsz,\n",
    "    num_workers=2,\n",
    "    collate_fn=XMLCollator(trn_dataset),\n",
    "    shuffle=True,\n",
    "    pin_memory=True)\n",
    "\n",
    "tst_loader = torch.utils.data.DataLoader(\n",
    "    tst_dataset,\n",
    "    batch_size=args.bsz,\n",
    "    num_workers=2,\n",
    "    collate_fn=XMLCollator(tst_dataset),\n",
    "    shuffle=False,\n",
    "    pin_memory=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "aefffc22",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-11-22T21:28:34.538343Z",
     "start_time": "2021-11-22T21:28:34.523616Z"
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "class Net(nn.Module):\n",
    "    def __init__(self, encoder, args):\n",
    "        super().__init__()\n",
    "        self.encoder = encoder\n",
    "        self.numy = args.numy\n",
    "        self.dropout = nn.Dropout(args.dropout)\n",
    "        if args.per_label_task:\n",
    "            self.w = nn.Sequential(nn.Linear(args.embed_dim, 2*args.embed_dim), \n",
    "                                   nn.ReLU(), \n",
    "                                   nn.Linear(2*args.embed_dim, 1))\n",
    "        else:\n",
    "            self.w = nn.Linear(args.embed_dim, args.numy)\n",
    "        \n",
    "    def get_device(self):\n",
    "        return list(self.parameters())[0].device\n",
    "    \n",
    "    def forward(self, b):\n",
    "        mask = b['xfts']['input_mask']\n",
    "        embs = self.encoder(b['xfts']['input_ids'], mask)\n",
    "        \n",
    "        if self.encoder.per_token_decoder:\n",
    "            embs = embs * mask.unsqueeze(-1) / mask.sum(dim=-1).reshape(-1, 1, 1)\n",
    "            embs = embs.sum(dim=1)\n",
    "        else:\n",
    "            embs = embs.squeeze()\n",
    "        out = self.w(self.dropout(embs))\n",
    "        return out.squeeze()\n",
    "    \n",
    "    def predict(self, tst_loader, K=100):\n",
    "        tst_X_Y = tst_loader.dataset.labels\n",
    "        data = np.zeros((tst_X_Y.shape[0], K))\n",
    "        inds = np.zeros((tst_X_Y.shape[0], K)).astype(np.int32)\n",
    "        indptr = np.arange(0, tst_X_Y.shape[0]*K+1, K)\n",
    "        self.eval()\n",
    "\n",
    "        with torch.no_grad():\n",
    "            for b in tqdm(tst_loader, leave=True, desc='Evaluating'):\n",
    "                b = ToD(b, self.get_device())\n",
    "                out = self(b)\n",
    "                top_data, top_inds = torch.topk(out, K)\n",
    "                data[b['ids'].cpu()] = top_data.detach().cpu().numpy()\n",
    "                inds[b['ids'].cpu()] = top_inds.detach().cpu().numpy()\n",
    "                del top_data, top_inds, b, out\n",
    "\n",
    "        torch.cuda.empty_cache()\n",
    "        score_mat = sp.csr_matrix((data.ravel(), inds.ravel(), indptr), tst_X_Y.shape)\n",
    "        \n",
    "        return score_mat\n",
    "    \n",
    "class OvABCELoss(nn.Module):\n",
    "    def __init__(self, args, reduction='mean'):\n",
    "        super(OvABCELoss, self).__init__()\n",
    "        if args.loss_with_logits:\n",
    "            self.criterion = torch.nn.BCEWithLogitsLoss(reduction=reduction)\n",
    "        else:\n",
    "            self.criterion = torch.nn.BCELoss(reduction=reduction)\n",
    "\n",
    "    def forward(self, model, b):\n",
    "        out = model(b)\n",
    "        targets = torch.zeros((out.shape[0], out.shape[1]+1), device=out.device).scatter_(1, b['y']['inds'], 1)[:, :-1]\n",
    "        loss = self.criterion(out, targets)\n",
    "        return loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "f6b36845",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-11-22T21:22:11.688150Z",
     "start_time": "2021-11-22T21:22:11.641518Z"
    }
   },
   "outputs": [],
   "source": [
    "net = Net(encoder, args)\n",
    "criterion = OvABCELoss(args)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "820f5a54",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-11-22T21:31:29.284314Z",
     "start_time": "2021-11-22T21:31:29.263640Z"
    }
   },
   "outputs": [],
   "source": [
    "optim_wrap = {\n",
    "    'xc' : {'class': torch.optim.Adam, 'params': [], 'args': {'lr': args.xc_lr}},\n",
    "    'enc': {'class': transformers.optimization.AdamW, 'params': [], \n",
    "            'args': {'lr': args.enc_lr, 'eps': 1e-06, 'weight_decay': 0.01}}\n",
    "    }\n",
    "\n",
    "for n,p in net.named_parameters():\n",
    "    if 'query_task_embedding' in n or p.shape[-1] == args.numy or p.shape[0] == args.numy: \n",
    "        optim_wrap['xc']['params'].append((n, p))\n",
    "    else: \n",
    "        optim_wrap['enc']['params'].append((n, p))\n",
    "        \n",
    "optims = []\n",
    "for k, v in optim_wrap.items():\n",
    "    if len(v['params']) > 0: optims.append(v['class']([x[1] for x in v['params']], **v['args']))\n",
    "        \n",
    "\n",
    "total_steps = len(trn_loader)*args.n_epochs\n",
    "schedulers = [transformers.get_linear_schedule_with_warmup(optim, num_warmup_steps=int(args.warmup*total_steps), num_training_steps=total_steps) for optim in optims]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "b84958ae",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-11-22T21:22:12.016671Z",
     "start_time": "2021-11-22T21:22:12.008128Z"
    }
   },
   "outputs": [],
   "source": [
    "net.to(args.device);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "8f2c592a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'class': torch.optim.adam.Adam,\n",
       " 'params': [('encoder.query_task_embedding.weight',\n",
       "   Parameter containing:\n",
       "   tensor([[ 0.1021,  2.1816,  1.3950,  ...,  0.1481, -0.6218,  0.3663],\n",
       "           [ 0.5220,  0.2766,  0.7901,  ...,  0.5506, -1.8529, -0.0192],\n",
       "           [ 0.9008, -0.6969, -0.5283,  ..., -0.0365, -1.0203, -0.9421],\n",
       "           ...,\n",
       "           [-0.8841, -0.3392,  0.0727,  ...,  0.4174,  1.1941,  1.9235],\n",
       "           [-0.2528,  0.4482, -1.5365,  ..., -2.2480, -0.8965,  0.2644],\n",
       "           [ 1.0314,  0.7671, -0.2131,  ...,  1.4414,  1.6199,  0.3878]],\n",
       "          device='cuda:0', requires_grad=True))],\n",
       " 'args': {'lr': 0.001}}"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "optim_wrap['xc']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "79193c72",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-11-22T21:13:10.974978Z",
     "start_time": "2021-11-22T21:13:10.800372Z"
    },
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ecb00ec2977c46c28448e876879db369",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch: 0, Loss: 0.0:   0%|          | 0/483 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
      "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mean loss after epoch 0/25: 5.3451E-02\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "94cd3ba177d847f79d0e6b2f7eb8f899",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Evaluating:   0%|          | 0/121 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
      "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "P@1\tP@5\tnDCG@1\tnDCG@5\tPSP@1\tPSP@5\tR@10\tR@20\tR@100\tMRR@10\n",
      "7.17\t4.52\t7.17\t5.19\t2.08\t2.33\t7.4\t12.65\t27.58\t12.76\n",
      "\n",
      "P@1 P@5 nDCG@1 nDCG@5 PSP@1 PSP@5 R@10 R@20 R@100 MRR@10\n",
      "7.17 4.52 7.17 5.19 2.08 2.33 7.4 12.65 27.58 12.76\n",
      "\n",
      "\u001b[94mFound new best model with nDCG@5: 5.19\n",
      "\u001b[0m\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "63406297956d4d78a06bb98640517038",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch: 0, Loss: 0.0:   0%|          | 0/483 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
      "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mean loss after epoch 1/25: 9.3175E-03\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "079e6caacef34f9bbfd9c104174d620f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch: 0, Loss: 0.0:   0%|          | 0/483 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
      "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mean loss after epoch 2/25: 8.9519E-03\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "552ee2a01f89436cacee83ae8362bbe5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Evaluating:   0%|          | 0/121 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
      "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "P@1\tP@5\tnDCG@1\tnDCG@5\tPSP@1\tPSP@5\tR@10\tR@20\tR@100\tMRR@10\n",
      "12.16\t7.4\t12.16\t8.63\t3.6\t3.9\t11.29\t17.05\t39.19\t19.91\n",
      "\n",
      "P@1 P@5 nDCG@1 nDCG@5 PSP@1 PSP@5 R@10 R@20 R@100 MRR@10\n",
      "12.16 7.4 12.16 8.63 3.6 3.9 11.29 17.05 39.19 19.91\n",
      "\n",
      "\u001b[94mFound new best model with nDCG@5: 8.63\n",
      "\u001b[0m\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "459651c65cc548f49e817a8a818998cc",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch: 0, Loss: 0.0:   0%|          | 0/483 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
      "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mean loss after epoch 3/25: 8.4119E-03\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "25737820ce5644008b8470189e3b20e5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch: 0, Loss: 0.0:   0%|          | 0/483 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
      "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mean loss after epoch 4/25: 7.6494E-03\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d64e97767b984bb18a703be0dd4ad23a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Evaluating:   0%|          | 0/121 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
      "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "P@1\tP@5\tnDCG@1\tnDCG@5\tPSP@1\tPSP@5\tR@10\tR@20\tR@100\tMRR@10\n",
      "32.06\t20.52\t32.06\t24.19\t10.66\t12.58\t27.57\t37.13\t60.05\t44.45\n",
      "\n",
      "P@1 P@5 nDCG@1 nDCG@5 PSP@1 PSP@5 R@10 R@20 R@100 MRR@10\n",
      "32.06 20.52 32.06 24.19 10.66 12.58 27.57 37.13 60.05 44.45\n",
      "\n",
      "\u001b[94mFound new best model with nDCG@5: 24.19\n",
      "\u001b[0m\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "da15b762dcdf4ca1a476011369be4b69",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch: 0, Loss: 0.0:   0%|          | 0/483 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
      "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mean loss after epoch 5/25: 7.0542E-03\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0fa3a59b90b44769b9d973c9de4b579c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch: 0, Loss: 0.0:   0%|          | 0/483 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
      "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mean loss after epoch 6/25: 6.5698E-03\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "bf4a07c630ab427a86f2a30bb6ba2795",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Evaluating:   0%|          | 0/121 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
      "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "P@1\tP@5\tnDCG@1\tnDCG@5\tPSP@1\tPSP@5\tR@10\tR@20\tR@100\tMRR@10\n",
      "48.46\t29.04\t48.46\t35.05\t17.88\t19.67\t37.76\t47.23\t69.32\t59.9\n",
      "\n",
      "P@1 P@5 nDCG@1 nDCG@5 PSP@1 PSP@5 R@10 R@20 R@100 MRR@10\n",
      "48.46 29.04 48.46 35.05 17.88 19.67 37.76 47.23 69.32 59.9\n",
      "\n",
      "\u001b[94mFound new best model with nDCG@5: 35.05\n",
      "\u001b[0m\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c247aaf4d32041b88a2040bd62ba582c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch: 0, Loss: 0.0:   0%|          | 0/483 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
      "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mean loss after epoch 7/25: 6.1617E-03\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f21e68fd4ca842ed9a786a40dab04dbf",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch: 0, Loss: 0.0:   0%|          | 0/483 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
      "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mean loss after epoch 8/25: 5.8805E-03\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7d85dc89c81f46efbfc64520f63c9b3a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Evaluating:   0%|          | 0/121 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
      "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "P@1\tP@5\tnDCG@1\tnDCG@5\tPSP@1\tPSP@5\tR@10\tR@20\tR@100\tMRR@10\n",
      "55.89\t34.35\t55.89\t41.16\t21.35\t24.07\t43.71\t53.89\t74.06\t66.77\n",
      "\n",
      "P@1 P@5 nDCG@1 nDCG@5 PSP@1 PSP@5 R@10 R@20 R@100 MRR@10\n",
      "55.89 34.35 55.89 41.16 21.35 24.07 43.71 53.89 74.06 66.77\n",
      "\n",
      "\u001b[94mFound new best model with nDCG@5: 41.16\n",
      "\u001b[0m\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "eeea0c92a7e54eed9bf8127718b04d88",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch: 0, Loss: 0.0:   0%|          | 0/483 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
      "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mean loss after epoch 9/25: 5.5313E-03\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5c9cc87ade914a819286448296a1270c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch: 0, Loss: 0.0:   0%|          | 0/483 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
      "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mean loss after epoch 10/25: 5.2119E-03\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f1ef9b505d1f49358d616ed8526a5d33",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Evaluating:   0%|          | 0/121 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
      "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "P@1\tP@5\tnDCG@1\tnDCG@5\tPSP@1\tPSP@5\tR@10\tR@20\tR@100\tMRR@10\n",
      "61.89\t37.71\t61.89\t45.34\t24.89\t27.79\t48.13\t57.93\t76.53\t71.74\n",
      "\n",
      "P@1 P@5 nDCG@1 nDCG@5 PSP@1 PSP@5 R@10 R@20 R@100 MRR@10\n",
      "61.89 37.71 61.89 45.34 24.89 27.79 48.13 57.93 76.53 71.74\n",
      "\n",
      "\u001b[94mFound new best model with nDCG@5: 45.34\n",
      "\u001b[0m\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b4cba90a4902443fb17fe3c38a466690",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch: 0, Loss: 0.0:   0%|          | 0/483 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
      "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mean loss after epoch 11/25: 4.9492E-03\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9d9a83406e774a1a8319bbdbd710185a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch: 0, Loss: 0.0:   0%|          | 0/483 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
      "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mean loss after epoch 12/25: 4.6633E-03\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a361377e90a941eab0cdcf11fbf92cbe",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Evaluating:   0%|          | 0/121 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
      "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "P@1\tP@5\tnDCG@1\tnDCG@5\tPSP@1\tPSP@5\tR@10\tR@20\tR@100\tMRR@10\n",
      "67.06\t40.58\t67.06\t48.86\t28.07\t30.94\t51.18\t60.84\t78.4\t75.87\n",
      "\n",
      "P@1 P@5 nDCG@1 nDCG@5 PSP@1 PSP@5 R@10 R@20 R@100 MRR@10\n",
      "67.06 40.58 67.06 48.86 28.07 30.94 51.18 60.84 78.4 75.87\n",
      "\n",
      "\u001b[94mFound new best model with nDCG@5: 48.86\n",
      "\u001b[0m\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f2a0e5539cc3416fb338327450aa68af",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch: 0, Loss: 0.0:   0%|          | 0/483 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
      "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mean loss after epoch 13/25: 4.3943E-03\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "49b7360b7bbf41229d81a6f9cbf82e56",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch: 0, Loss: 0.0:   0%|          | 0/483 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
      "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mean loss after epoch 14/25: 4.1377E-03\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2b4fa42bf36e47d585c6584efa94a8c8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Evaluating:   0%|          | 0/121 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
      "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "P@1\tP@5\tnDCG@1\tnDCG@5\tPSP@1\tPSP@5\tR@10\tR@20\tR@100\tMRR@10\n",
      "67.09\t41.96\t67.09\t50.16\t28.58\t32.37\t52.28\t61.61\t79.06\t76.28\n",
      "\n",
      "P@1 P@5 nDCG@1 nDCG@5 PSP@1 PSP@5 R@10 R@20 R@100 MRR@10\n",
      "67.09 41.96 67.09 50.16 28.58 32.37 52.28 61.61 79.06 76.28\n",
      "\n",
      "\u001b[94mFound new best model with nDCG@5: 50.16\n",
      "\u001b[0m\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2c42270b3c9e4f3eb5582b05eb7c9c1e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch: 0, Loss: 0.0:   0%|          | 0/483 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
      "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mean loss after epoch 15/25: 3.8690E-03\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f89116867e09470887403cedb8437790",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch: 0, Loss: 0.0:   0%|          | 0/483 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
      "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mean loss after epoch 16/25: 3.5955E-03\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c620b98beb054d67bedd3a12cb6cda8a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Evaluating:   0%|          | 0/121 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
      "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "P@1\tP@5\tnDCG@1\tnDCG@5\tPSP@1\tPSP@5\tR@10\tR@20\tR@100\tMRR@10\n",
      "69.42\t43.33\t69.42\t51.99\t30.45\t34.61\t53.72\t63.02\t79.68\t78.21\n",
      "\n",
      "P@1 P@5 nDCG@1 nDCG@5 PSP@1 PSP@5 R@10 R@20 R@100 MRR@10\n",
      "69.42 43.33 69.42 51.99 30.45 34.61 53.72 63.02 79.68 78.21\n",
      "\n",
      "\u001b[94mFound new best model with nDCG@5: 51.99\n",
      "\u001b[0m\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3a6b6a9ecc154593a7b226ba75ceea60",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch: 0, Loss: 0.0:   0%|          | 0/483 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
      "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mean loss after epoch 17/25: 3.3243E-03\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "23a57f1eee914281a6754bb8ba19c982",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch: 0, Loss: 0.0:   0%|          | 0/483 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
      "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_28665/1186784597.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     10\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcuda\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mamp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mautocast\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0menabled\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mamp\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m             \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcriterion\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnet\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mb\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 12\u001b[0;31m         \u001b[0mloss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     13\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0moptim\u001b[0m \u001b[0;32min\u001b[0m \u001b[0moptims\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0moptim\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     14\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0msch\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mschedulers\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0msch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.7/site-packages/torch/_tensor.py\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(self, gradient, retain_graph, create_graph, inputs)\u001b[0m\n\u001b[1;32m    253\u001b[0m                 \u001b[0mcreate_graph\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcreate_graph\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    254\u001b[0m                 inputs=inputs)\n\u001b[0;32m--> 255\u001b[0;31m         \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mautograd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgradient\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    256\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    257\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mregister_hook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.7/site-packages/torch/autograd/__init__.py\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables, inputs)\u001b[0m\n\u001b[1;32m    147\u001b[0m     Variable._execution_engine.run_backward(\n\u001b[1;32m    148\u001b[0m         \u001b[0mtensors\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgrad_tensors_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 149\u001b[0;31m         allow_unreachable=True, accumulate_grad=True)  # allow_unreachable flag\n\u001b[0m\u001b[1;32m    150\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    151\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "scaler = torch.cuda.amp.GradScaler()\n",
    "best_ndcg = -100\n",
    "for epoch in range(args.n_epochs):\n",
    "    net.train()\n",
    "    cum_loss = 0; ctr = 0\n",
    "    t = tqdm(trn_loader, desc='Epoch: 0, Loss: 0.0', leave=True)\n",
    "          \n",
    "    for b in t:        \n",
    "        for optim in optims: optim.zero_grad()\n",
    "        b = ToD(b, args.device)\n",
    "        with torch.cuda.amp.autocast(enabled=args.amp):\n",
    "            loss = criterion(net, b)\n",
    "            \n",
    "        if args.amp:\n",
    "            scaler.scale(loss).backward()\n",
    "            for optim in optims: scaler.step(optim)\n",
    "            scaler.update()\n",
    "        else:\n",
    "            loss.backward()\n",
    "            for optim in optims: optim.step()\n",
    "                \n",
    "        for sch in schedulers: sch.step()\n",
    "        cum_loss += loss.item()\n",
    "        ctr += 1\n",
    "        t.set_description('Epoch: %d/%d, Loss: %.4E'%(epoch, args.n_epochs, (cum_loss/ctr)), refresh=True)\n",
    "    \n",
    "    print(f'mean loss after epoch {epoch}/{args.n_epochs}: {\"%.4E\"%(cum_loss/ctr)}', flush=True)\n",
    "    if epoch%args.eval_interval == 0 or epoch == (args.n_epochs-1):\n",
    "        score_mat = net.predict(tst_loader)\n",
    "        metrics = XCMetrics(score_mat, tst_X_Y, inv_prop, method=args.expname, disp=True)\n",
    "\n",
    "        if metrics.loc[args.expname]['nDCG@5'] > best_ndcg:\n",
    "            best_ndcg = metrics.loc[args.expname]['nDCG@5']\n",
    "            print(_c(f'Found new best model with nDCG@5: {\"%.2f\"%best_ndcg}\\n', attr='blue'))\n",
    "            sp.save_npz(f'{OUT_DIR}/score_mat.npz', score_mat)\n",
    "            metrics.to_csv(open(f'{OUT_DIR}/metrics.tsv', 'a'), sep='\\t')\n",
    "            torch.save(net.state_dict(), f'{OUT_DIR}/model.pt')\n",
    "    sys.stdout.flush()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "d8536a83",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-11-18T21:38:58.932235Z",
     "start_time": "2021-11-18T21:38:58.913729Z"
    }
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'model' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_5437/1918826831.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mnum_params\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0;32mfor\u001b[0m \u001b[0mp\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mparameters\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m     \u001b[0mnum_params\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mprod\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mnum_params\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'model' is not defined"
     ]
    }
   ],
   "source": [
    "num_params = 0\n",
    "for p in model.parameters():\n",
    "    num_params += np.prod(p.shape)\n",
    "\n",
    "num_params"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:xc]",
   "language": "python",
   "name": "conda-env-xc-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
