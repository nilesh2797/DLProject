{
  "nbformat": 4,
  "nbformat_minor": 5,
  "metadata": {
    "colab": {
      "name": "perceiver_xc_imdb.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "machine_shape": "hm"
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zh3Ylqqoi1T8",
        "outputId": "28bc1f9a-10dc-402c-9c89-d5b91c74234f"
      },
      "source": [
        "!git clone https://github.com/nilesh2797/DLProject.git"
      ],
      "id": "zh3Ylqqoi1T8",
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cloning into 'DLProject'...\n",
            "remote: Enumerating objects: 97, done.\u001b[K\n",
            "remote: Counting objects: 100% (97/97), done.\u001b[K\n",
            "remote: Compressing objects: 100% (70/70), done.\u001b[K\n",
            "remote: Total 97 (delta 45), reused 71 (delta 22), pack-reused 0\u001b[K\n",
            "Unpacking objects: 100% (97/97), done.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "c31a_3RwNiu6",
        "outputId": "6397db93-2819-45bd-8866-d29eed09d1d5"
      },
      "source": [
        "%cd DLProject/"
      ],
      "id": "c31a_3RwNiu6",
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/DLProject\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8RLBOmTnOAYS"
      },
      "source": [
        "!pip3 install dm-haiku\n",
        "!pip3 install --upgrade einops\n",
        "!pip3 install transformers\n"
      ],
      "id": "8RLBOmTnOAYS",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 17
        },
        "id": "8c3c640c",
        "outputId": "6f9b3c9e-96af-4227-8df4-27a2c6597702"
      },
      "source": [
        "from IPython.core.display import display, HTML\n",
        "display(HTML(\"<style>.container { width:100% !important; }</style>\"))"
      ],
      "id": "8c3c640c",
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<style>.container { width:100% !important; }</style>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ca772133",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "069ea99e-216e-424f-f229-1215bf0c600c"
      },
      "source": [
        "# downlaod deepmind's pretrained language model\n",
        "!wget -O deepmind_assets/language_perceiver_io_bytes.pickle https://storage.googleapis.com/perceiver_io/language_perceiver_io_bytes.pickle"
      ],
      "id": "ca772133",
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--2021-12-06 13:10:59--  https://storage.googleapis.com/perceiver_io/language_perceiver_io_bytes.pickle\n",
            "Resolving storage.googleapis.com (storage.googleapis.com)... 173.194.193.128, 173.194.195.128, 173.194.197.128, ...\n",
            "Connecting to storage.googleapis.com (storage.googleapis.com)|173.194.193.128|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 804479532 (767M) [application/octet-stream]\n",
            "Saving to: ‘deepmind_assets/language_perceiver_io_bytes.pickle’\n",
            "\n",
            "deepmind_assets/lan 100%[===================>] 767.21M   146MB/s    in 5.6s    \n",
            "\n",
            "2021-12-06 13:11:05 (136 MB/s) - ‘deepmind_assets/language_perceiver_io_bytes.pickle’ saved [804479532/804479532]\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aa32b428"
      },
      "source": [
        "from perceiver_io.perceiver_lm import PerceiverLM\n",
        "from perceiver_io.perceiver_in import PerceiverIN\n",
        "\n",
        "import os, sys\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import transformers\n",
        "\n",
        "from deepmind_assets import bytes_tokenizer\n",
        "import numpy as np\n",
        "import scipy.sparse as sp\n",
        "from tqdm.notebook import tqdm\n",
        "import scipy.sparse as sp\n",
        "# import xclib.evaluation.xc_metrics as xc_metrics\n",
        "# from utils import csr_to_pad_tensor, ToD, read_sparse_mat, XCMetrics, _c\n",
        "from torch.nn.utils.rnn import pad_sequence\n",
        "import copy\n",
        "import random\n",
        "from torchtext.datasets import IMDB\n",
        "\n",
        "\n",
        "# The tokenizer is just UTF-8 encoding (with an offset)\n",
        "tokenizer = bytes_tokenizer.BytesTokenizer()"
      ],
      "id": "aa32b428",
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "b0b3fcf9"
      },
      "source": [
        "command = \"--dataset IMDB\"\n",
        "\n",
        "import argparse\n",
        "parser = argparse.ArgumentParser()\n",
        "parser.add_argument('--project', default='PerceiverIO_fullgrad_1query_task')\n",
        "parser.add_argument('--dataset', default='IMDB')\n",
        "parser.add_argument('--device', type=str, default='cuda')\n",
        "\n",
        "args = parser.parse_args(command.split())"
      ],
      "id": "b0b3fcf9",
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "a7cddcb9"
      },
      "source": [
        "args.expname = args.project\n",
        "args.maxlen = 2048\n",
        "args.vocab_size = 262\n",
        "args.embed_dim = 768\n",
        "args.num_latents = 256\n",
        "args.numy = 2\n",
        "\n",
        "args.n_epochs = 25\n",
        "args.xc_lr = 1e-3\n",
        "args.enc_lr = 1e-4\n",
        "args.bsz = 8\n",
        "args.dropout = 0.5\n",
        "args.warmup = 0.1\n",
        "args.loss_with_logits = True\n",
        "args.amp = True\n",
        "args.eval_interval = 2\n",
        "\n",
        "args.per_label_task = False\n",
        "args.per_token_decoder = False\n",
        "\n",
        "args.mode = 'all'\n",
        "# args.mode = 'decoder+classifier'\n",
        "# args.mode = 'pre_san+decoder+classifier'\n",
        "# args.mode = 'pre_san+san_layer_norm+decoder+classifier'\n",
        "\n",
        "OUT_DIR = f'{args.project}/{args.dataset}'\n",
        "os.makedirs(OUT_DIR, exist_ok=True)"
      ],
      "id": "a7cddcb9",
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bd29aa79",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "1cbb9653-3a34-4629-c441-c1da56c48e12"
      },
      "source": [
        "encoder = PerceiverLM(vocab_size=args.vocab_size, \n",
        "                      max_seq_len=args.maxlen, \n",
        "                      embedding_dim=args.embed_dim, \n",
        "                      num_latents=args.num_latents, \n",
        "                      latent_dim=1280, \n",
        "                      qk_out_dim=256, \n",
        "                      dropout=0,\n",
        "                      num_self_attn_per_block=26, \n",
        "                      per_token_decoder=args.per_token_decoder, \n",
        "                      num_query_tasks=args.numy if args.per_label_task else 1)\n",
        "\n",
        "encoder.load_pretrained(\"deepmind_assets/language_perceiver_io_bytes.pickle\")"
      ],
      "id": "bd29aa79",
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "_IncompatibleKeys(missing_keys=['query_task_embedding.weight'], unexpected_keys=[])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AZGWArKdRRcL",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "44667d21-39ef-4e3e-bbcc-417980f3ff6f"
      },
      "source": [
        "trainset = IMDB(root='.data', split='train')\n",
        "testset = IMDB(root='.data', split='test')"
      ],
      "id": "AZGWArKdRRcL",
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 84.1M/84.1M [00:02<00:00, 38.2MB/s]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Jn0eMIRNcDk6"
      },
      "source": [
        "train_set = [elem for elem in trainset]\n",
        "test_set = [elem for elem in testset]\n",
        "random.shuffle(train_set)\n",
        "random.shuffle(test_set)\n"
      ],
      "id": "Jn0eMIRNcDk6",
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6fCqZqgLWTBQ"
      },
      "source": [
        "trn_loader = torch.utils.data.DataLoader(\n",
        "    train_set,\n",
        "    batch_size=args.bsz,\n",
        "    num_workers=1,\n",
        "    pin_memory=True)\n",
        "\n",
        "tst_loader = torch.utils.data.DataLoader(\n",
        "    test_set,\n",
        "    batch_size=args.bsz,\n",
        "    num_workers=1,\n",
        "    pin_memory=True)"
      ],
      "id": "6fCqZqgLWTBQ",
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aefffc22",
        "scrolled": true
      },
      "source": [
        "class Net(nn.Module):\n",
        "    def __init__(self, encoder, args):\n",
        "        super().__init__()\n",
        "        self.encoder = encoder\n",
        "        self.numy = args.numy\n",
        "        self.dropout = nn.Dropout(args.dropout)\n",
        "        if args.per_label_task:\n",
        "            self.w = nn.Sequential(nn.Linear(args.embed_dim, 2*args.embed_dim), \n",
        "                                   nn.ReLU(), \n",
        "                                   nn.Linear(2*args.embed_dim, 1))\n",
        "        else:\n",
        "            self.w = nn.Linear(args.embed_dim, args.numy)\n",
        "        \n",
        "    def get_device(self):\n",
        "        return list(self.parameters())[0].device\n",
        "    \n",
        "    def forward(self, inputs, mask):\n",
        "        # mask = b['xfts']['input_mask']\n",
        "        embs = self.encoder(inputs, mask)\n",
        "        \n",
        "        if self.encoder.per_token_decoder:\n",
        "            embs = embs * mask.unsqueeze(-1) / mask.sum(dim=-1).reshape(-1, 1, 1)\n",
        "            embs = embs.sum(dim=1)\n",
        "        else:\n",
        "            embs = embs.squeeze()\n",
        "        out = self.w(self.dropout(embs))\n",
        "        return out.squeeze()"
      ],
      "id": "aefffc22",
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "f6b36845"
      },
      "source": [
        "net = Net(encoder, args)\n",
        "criterion = nn.CrossEntropyLoss()"
      ],
      "id": "f6b36845",
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "820f5a54"
      },
      "source": [
        "optim_wrap = {\n",
        "    'xc' : {'class': torch.optim.Adam, 'params': [], 'args': {'lr': args.xc_lr}},\n",
        "    'enc': {'class': transformers.optimization.AdamW, 'params': [], \n",
        "            'args': {'lr': args.enc_lr, 'eps': 1e-06, 'weight_decay': 0.01}}\n",
        "    }\n",
        "\n",
        "for n,p in net.named_parameters():\n",
        "    if 'query_task_embedding' in n or p.shape[-1] == args.numy or p.shape[0] == args.numy: \n",
        "        optim_wrap['xc']['params'].append((n, p))\n",
        "    else: \n",
        "        optim_wrap['enc']['params'].append((n, p))\n",
        "        \n",
        "optims = []\n",
        "for k, v in optim_wrap.items():\n",
        "    if len(v['params']) > 0: optims.append(v['class']([x[1] for x in v['params']], **v['args']))\n",
        "        \n",
        "\n",
        "total_steps = len(trn_loader)*args.n_epochs\n",
        "schedulers = [transformers.get_linear_schedule_with_warmup(optim, num_warmup_steps=int(args.warmup*total_steps), num_training_steps=total_steps) for optim in optims]"
      ],
      "id": "820f5a54",
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wwIC3_IBF47g"
      },
      "source": [
        "# Sets requires_grad=False for some params and Prints all parameter names which have requires_grad=True\n",
        "for n, p in net.named_parameters():\n",
        "    if n.startswith('encoder.'):\n",
        "        if args.mode == 'decoder+classifier':\n",
        "            if not n.startswith('encoder.query') and not n.startswith('encoder.perceiver.decoder'):\n",
        "                p.requires_grad = False\n",
        "                continue\n",
        "        if args.mode == 'pre_san+decoder+classifier':\n",
        "            if n.startswith('encoder.perceiver.encoder.self_attention'):\n",
        "                p.requires_grad = False\n",
        "                continue\n",
        "        if args.mode == 'pre_san+san_layer_norm+decoder+classifier':\n",
        "            if n.startswith('encoder.perceiver.encoder.self_attention') and not 'layer_norm' in n:\n",
        "                p.requires_grad = False\n",
        "                continue\n",
        "    print(n)"
      ],
      "id": "wwIC3_IBF47g",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "b84958ae"
      },
      "source": [
        "net.to(args.device);"
      ],
      "id": "b84958ae",
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "y60R_pEOXlNR"
      },
      "source": [
        "def pad(max_sequence_length: int, inputs, input_mask):\n",
        "    input_len = inputs.shape[1]\n",
        "    if input_len > max_sequence_length:\n",
        "      return inputs[0,:max_sequence_length][None], input_mask[0,:max_sequence_length][None]\n",
        "    pad_len = max_sequence_length - input_len\n",
        "    padded_inputs = np.pad(\n",
        "      inputs,\n",
        "      pad_width=((0, 0), (0, pad_len)),\n",
        "      constant_values=tokenizer.pad_token)\n",
        "    padded_mask = np.pad(\n",
        "      input_mask,\n",
        "      pad_width=((0, 0), (0, pad_len)),\n",
        "      constant_values=0)\n",
        "    return padded_inputs, padded_mask"
      ],
      "id": "y60R_pEOXlNR",
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "79193c72",
        "scrolled": true
      },
      "source": [
        "scaler = torch.cuda.amp.GradScaler()\n",
        "train_loss = []\n",
        "valid_accuracy = []\n",
        "best_valid_acc = 0\n",
        "best_epoch = 0\n",
        "for epoch in range(args.n_epochs):\n",
        "    net.train()\n",
        "    cum_loss = 0; ctr = 0\n",
        "    t = tqdm(trn_loader, desc='Epoch: 0, Loss: 0.0', leave=True)\n",
        "          \n",
        "    for y, X in t:        \n",
        "        for optim in optims: optim.zero_grad()\n",
        "        # b = ToD(b, args.device)\n",
        "        input_tokens = []\n",
        "        input_mask = []\n",
        "        for input_str in X:\n",
        "          tokens = tokenizer.to_int(input_str)[None]\n",
        "          mask = np.ones_like(tokens)\n",
        "\n",
        "          inputs, mask = pad(args.maxlen, tokens, mask)\n",
        "          input_tokens.append(inputs[0,:])\n",
        "          input_mask.append(mask[0,:])\n",
        "\n",
        "        input_tokens = np.array(input_tokens)\n",
        "        input_mask = np.array(input_mask)\n",
        "\n",
        "        out = net.forward(torch.tensor(input_tokens).to(args.device), torch.tensor(input_mask).to(args.device))\n",
        "\n",
        "        y = torch.tensor([0 if elem == 'neg' else 1 for elem in y])\n",
        "        with torch.cuda.amp.autocast(enabled=args.amp):\n",
        "            loss = criterion(out, y.to(args.device))\n",
        "            \n",
        "        if args.amp:\n",
        "            scaler.scale(loss).backward()\n",
        "            for optim in optims: scaler.step(optim)\n",
        "            scaler.update()\n",
        "        else:\n",
        "            loss.backward()\n",
        "            for optim in optims: optim.step()\n",
        "                \n",
        "        for sch in schedulers: sch.step()\n",
        "        cum_loss += loss.item()\n",
        "        ctr += 1\n",
        "        t.set_description('Epoch: %d/%d, Loss: %.4E'%(epoch, args.n_epochs, (cum_loss/ctr)), refresh=True)\n",
        "        if ctr%1000 == 0:\n",
        "          train_loss.append(cum_loss/ctr)\n",
        "    print(f'mean loss after epoch {epoch}/{args.n_epochs}: {\"%.4E\"%(cum_loss/ctr)}', flush=True)\n",
        "    if epoch%args.eval_interval == 0 or epoch == (args.n_epochs-1):\n",
        "        print(\"Testing on validation data\")\n",
        "        corrects = 0\n",
        "        net.eval()\n",
        "        t = tqdm(tst_loader, leave=True)\n",
        "        for y, X in t:        \n",
        "            input_tokens = []\n",
        "            input_mask = []\n",
        "            for input_str in X:\n",
        "              tokens = tokenizer.to_int(input_str)[None]\n",
        "              mask = np.ones_like(tokens)\n",
        "\n",
        "              inputs, mask = pad(args.maxlen, tokens, mask)\n",
        "              input_tokens.append(inputs[0,:])\n",
        "              input_mask.append(mask[0,:])\n",
        "\n",
        "            input_tokens = np.array(input_tokens)\n",
        "            input_mask = np.array(input_mask)\n",
        "\n",
        "            out = net.forward(torch.tensor(input_tokens).to(args.device), torch.tensor(input_mask).to(args.device))\n",
        "            y = torch.tensor([0 if elem == 'neg' else 1 for elem in y])\n",
        "            corrects += int(sum(out.argmax(dim=1) == y.to(args.device)).cpu().detach().item())\n",
        "        valid_accuracy.append(corrects/args.bsz/len(tst_loader))\n",
        "        print(valid_accuracy[-1])\n",
        "\n",
        "        if valid_accuracy[-1] > best_valid_acc:\n",
        "            best_valid_acc = valid_accuracy[-1]\n",
        "            print(f'Found new best model with Accuracy: {\"%.5f\"%best_valid_acc}\\n')\n",
        "            torch.save(net.state_dict(), f'{OUT_DIR}/model.pt')\n",
        "            best_epoch = epoch\n",
        "    sys.stdout.flush()\n",
        "    np.save(f'{OUT_DIR}/train_loss.npy', np.array(train_loss))\n",
        "    np.save(f'{OUT_DIR}/valid_acc.npy', np.array(valid_accuracy))\n",
        "\n",
        "print(\"Best epoch\", best_epoch)"
      ],
      "id": "79193c72",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aLouovwBeQWw"
      },
      "source": [
        "# Load final trained model and evaluat on train set\n",
        "\n",
        "net.load_state_dict(torch.load(f'{OUT_DIR}/model.pt'))\n",
        "corrects = 0\n",
        "net.eval()\n",
        "t = tqdm(trn_loader, leave=True)\n",
        "for y, X in t:        \n",
        "    input_tokens = []\n",
        "    input_mask = []\n",
        "    for input_str in X:\n",
        "      tokens = tokenizer.to_int(input_str)[None]\n",
        "      mask = np.ones_like(tokens)\n",
        "\n",
        "      inputs, mask = pad(args.maxlen, tokens, mask)\n",
        "      input_tokens.append(inputs[0,:])\n",
        "      input_mask.append(mask[0,:])\n",
        "\n",
        "    input_tokens = np.array(input_tokens)\n",
        "    input_mask = np.array(input_mask)\n",
        "\n",
        "    out = net.forward(torch.tensor(input_tokens).to(args.device), torch.tensor(input_mask).to(args.device))\n",
        "    y = torch.tensor([0 if elem == 'neg' else 1 for elem in y])\n",
        "    corrects += int(sum(out.argmax(dim=1) == y.to(args.device)).cpu().detach().item())\n",
        "print(corrects/args.bsz/len(trn_loader))"
      ],
      "id": "aLouovwBeQWw",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SreyjjpKIOwX"
      },
      "source": [
        ""
      ],
      "id": "SreyjjpKIOwX",
      "execution_count": null,
      "outputs": []
    }
  ]
}