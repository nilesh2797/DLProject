{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "8c3c640c",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-11-29T22:42:26.208039Z",
     "start_time": "2021-11-29T22:42:26.197057Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>.container { width:100% !important; }</style>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from IPython.core.display import display, HTML\n",
    "display(HTML(\"<style>.container { width:100% !important; }</style>\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "ca772133",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-11-29T22:42:27.488080Z",
     "start_time": "2021-11-29T22:42:27.486226Z"
    }
   },
   "outputs": [],
   "source": [
    "# downlaod deepmind's pretrained language model\n",
    "# !wget -O deepmind_assets/language_perceiver_io_bytes.pickle https://storage.googleapis.com/perceiver_io/language_perceiver_io_bytes.pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "aa32b428",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-11-29T22:42:30.699774Z",
     "start_time": "2021-11-29T22:42:28.007485Z"
    }
   },
   "outputs": [],
   "source": [
    "from perceiver_io.perceiver_lm import PerceiverLM\n",
    "\n",
    "import os, sys\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "import transformers\n",
    "\n",
    "from deepmind_assets import bytes_tokenizer\n",
    "import numpy as np\n",
    "import scipy.sparse as sp\n",
    "from tqdm.notebook import tqdm\n",
    "import scipy.sparse as sp\n",
    "import xclib.evaluation.xc_metrics as xc_metrics\n",
    "from utils import csr_to_pad_tensor, ToD, read_sparse_mat, XCMetrics, _c\n",
    "from torch.nn.utils.rnn import pad_sequence\n",
    "\n",
    "# The tokenizer is just UTF-8 encoding (with an offset)\n",
    "tokenizer = bytes_tokenizer.BytesTokenizer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "b0b3fcf9",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-11-29T22:42:30.704929Z",
     "start_time": "2021-11-29T22:42:30.701350Z"
    }
   },
   "outputs": [],
   "source": [
    "command = \"--dataset cifar10\"\n",
    "\n",
    "import argparse\n",
    "parser = argparse.ArgumentParser()\n",
    "parser.add_argument('--project', default='PerceiverIO')\n",
    "parser.add_argument('--dataset', default='EURLex-4K')\n",
    "parser.add_argument('--device', type=str, default='cuda:0')\n",
    "\n",
    "args = parser.parse_args(command.split())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "a7cddcb9",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-11-29T22:42:37.545272Z",
     "start_time": "2021-11-29T22:42:37.541642Z"
    }
   },
   "outputs": [],
   "source": [
    "args.expname = f'{args.project}-image'\n",
    "args.maxlen = 2048\n",
    "args.vocab_size = 262\n",
    "args.embed_dim = 768\n",
    "args.num_latents = 256\n",
    "\n",
    "args.n_epochs = 10\n",
    "args.lr = 1e-4\n",
    "args.bsz = 16\n",
    "args.dropout = 0.5\n",
    "args.warmup = 0.1\n",
    "args.loss_with_logits = True\n",
    "args.amp = False\n",
    "args.eval_interval = 2\n",
    "\n",
    "args.per_label_task = False\n",
    "args.per_token_decoder = False\n",
    "\n",
    "OUT_DIR = f'Results/{args.expname}/{args.dataset}'\n",
    "os.makedirs(OUT_DIR, exist_ok=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "f760d136",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-11-29T22:42:40.260767Z",
     "start_time": "2021-11-29T22:42:40.256323Z"
    }
   },
   "outputs": [],
   "source": [
    "args.img_size = 32\n",
    "if args.dataset == 'tiny-imagenet':\n",
    "    args.img_size = 64\n",
    "elif args.dataset == 'stl10':\n",
    "    args.img_size = 96\n",
    "elif args.dataset == 'cifar10':\n",
    "    args.img_size = 32\n",
    "    \n",
    "transform_train = transforms.Compose([\n",
    "    transforms.Resize(args.img_size),\n",
    "    transforms.RandomCrop(args.img_size, padding=4),\n",
    "    transforms.RandomHorizontalFlip(),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize((0.4914, 0.4822, 0.4465), (0.2023, 0.1994, 0.2010)),\n",
    "])\n",
    "\n",
    "transform_test = transforms.Compose([\n",
    "    transforms.Resize(args.img_size),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize((0.4914, 0.4822, 0.4465), (0.2023, 0.1994, 0.2010)),\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "b1ca9b2e",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-11-29T22:42:41.505899Z",
     "start_time": "2021-11-29T22:42:40.593410Z"
    }
   },
   "outputs": [],
   "source": [
    "if args.dataset == 'cifar10':\n",
    "    trainset = torchvision.datasets.CIFAR10(root='./data', train=True, download=False, transform=transform_train)\n",
    "    testset = torchvision.datasets.CIFAR10(root='./data', train=False, download=False, transform=transform_test)\n",
    "    args.numy = 10\n",
    "elif args.dataset == 'tiny-imagenet':\n",
    "    fix_tin_val_folder('./data/tiny-imagenet-200/val')\n",
    "    trainset = torchvision.datasets.ImageFolder(root='./data/tiny-imagenet-200/train', transform=transform_train)\n",
    "    testset = torchvision.datasets.ImageFolder(root='./data/tiny-imagenet-200/val', transform=transform_test)\n",
    "    args.numy = 200\n",
    "elif args.dataset == 'stl10':\n",
    "    trainset = torchvision.datasets.STL10(root='./data', split='train', download=False, transform=transform_train)\n",
    "    testset = torchvision.datasets.STL10(root='./data', split='test', download=False, transform=transform_test)\n",
    "    args.numy = 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "bd29aa79",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-11-29T22:42:45.074316Z",
     "start_time": "2021-11-29T22:42:41.507167Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_IncompatibleKeys(missing_keys=['query_task_embedding.weight'], unexpected_keys=[])\n"
     ]
    }
   ],
   "source": [
    "encoder = PerceiverLM(vocab_size=args.vocab_size, \n",
    "                      max_seq_len=args.maxlen, \n",
    "                      embedding_dim=args.embed_dim, \n",
    "                      num_latents=args.num_latents, \n",
    "                      latent_dim=1280, \n",
    "                      qk_out_dim=256, \n",
    "                      dropout=0,\n",
    "                      num_self_attn_per_block=26, \n",
    "                      per_token_decoder=args.per_token_decoder, \n",
    "                      num_query_tasks=args.numy if args.per_label_task else 1)\n",
    "\n",
    "encoder.load_pretrained(\"deepmind_assets/language_perceiver_io_bytes.pickle\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "d2dcd9af",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-11-29T22:42:47.668981Z",
     "start_time": "2021-11-29T22:42:47.662361Z"
    }
   },
   "outputs": [],
   "source": [
    "from einops import rearrange, repeat\n",
    "from einops.layers.torch import Rearrange"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "7ed43446",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-11-29T22:42:48.029042Z",
     "start_time": "2021-11-29T22:42:48.026569Z"
    }
   },
   "outputs": [],
   "source": [
    "args.patch_height = 4\n",
    "args.patch_width = 4\n",
    "args.num_patches = (args.img_size // args.patch_height) * (args.img_size // args.patch_width)\n",
    "args.patch_dim = 3 * args.patch_height * args.patch_width"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "afc4febb",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-11-29T22:42:49.856513Z",
     "start_time": "2021-11-29T22:42:49.854017Z"
    }
   },
   "outputs": [],
   "source": [
    "## Sanity check for encoder with per_token_decoder=True\n",
    "\n",
    "# input_str = \"This is an incomplete sentence where some words are missing.\"\n",
    "# input_tokens = tokenizer.to_int(input_str)\n",
    "\n",
    "# # Mask \" missing.\". Note that the model performs much better if the masked chunk\n",
    "# # starts with a space.\n",
    "# input_tokens[51:60] = tokenizer.mask_token\n",
    "# print(\"Tokenized string without masked bytes:\")\n",
    "# print(tokenizer.to_string(input_tokens))\n",
    "\n",
    "# #@title Pad and reshape inputs\n",
    "# inputs = input_tokens[None]\n",
    "# input_mask = np.ones_like(inputs)\n",
    "\n",
    "# def pad(max_sequence_length: int, inputs, input_mask):\n",
    "#     input_len = inputs.shape[1]\n",
    "#     assert input_len <= max_sequence_length\n",
    "#     pad_len = max_sequence_length - input_len\n",
    "#     padded_inputs = np.pad(\n",
    "#       inputs,\n",
    "#       pad_width=((0, 0), (0, pad_len)),\n",
    "#       constant_values=tokenizer.pad_token)\n",
    "#     padded_mask = np.pad(\n",
    "#       input_mask,\n",
    "#       pad_width=((0, 0), (0, pad_len)),\n",
    "#       constant_values=0)\n",
    "#     return padded_inputs, padded_mask\n",
    "\n",
    "# inputs, input_mask = pad(args.maxlen, inputs, input_mask)\n",
    "\n",
    "# encoder.eval()\n",
    "# mask = torch.tensor(input_mask)\n",
    "# input_ids = torch.tensor(inputs)\n",
    "# out = encoder.forward(input_ids, mask)\n",
    "\n",
    "# embs = out * mask.unsqueeze(-1) / mask.sum(dim=-1)\n",
    "\n",
    "# logits = torch.matmul(out, encoder.token_embedding.weight.T) + encoder.decoder_token_bias\n",
    "# masked_tokens_predictions = logits[0, 51:60].argmax(dim=-1)\n",
    "# print(\"Greedy predictions:\")\n",
    "# print(masked_tokens_predictions)\n",
    "# print()\n",
    "# print(\"Predicted string:\")\n",
    "# print(tokenizer.to_string(masked_tokens_predictions.cpu().detach().numpy()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "4cc9206e",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-11-29T22:42:50.179998Z",
     "start_time": "2021-11-29T22:42:50.173994Z"
    }
   },
   "outputs": [],
   "source": [
    "class XMLDataset(torch.utils.data.Dataset):\n",
    "    def __init__(self, inputs, labels, tokenizer, maxlen):\n",
    "        self.maxlen = maxlen\n",
    "        self.input_ids = pad_sequence([torch.LongTensor(tokenizer.to_int(x)[:maxlen]) for x in inputs], batch_first=True, padding_value=0)\n",
    "        self.input_mask = (self.input_ids != 0).long()\n",
    "        self.labels = labels\n",
    "            \n",
    "    def __getitem__(self, index):\n",
    "        return index\n",
    "    \n",
    "    def get_fts(self, indices, source='point'):\n",
    "        input_mask = self.input_mask[indices]\n",
    "        max_batch_seq_len = input_mask.sum(dim=-1).max()\n",
    "        return {'input_ids': self.input_ids[indices, :max_batch_seq_len], 'input_mask': input_mask[:, :max_batch_seq_len]}\n",
    "   \n",
    "    def __len__(self):\n",
    "        return self.labels.shape[0]\n",
    "    \n",
    "class XMLCollator():\n",
    "    def __init__(self, dataset):\n",
    "        self.numy = dataset.labels.shape[1]\n",
    "        self.dataset = dataset\n",
    "    \n",
    "    def __call__(self, batch):\n",
    "        ids = torch.LongTensor(batch)\n",
    "        batch_data = {'batch_size': torch.LongTensor([len(batch)]),\n",
    "                      'numy': torch.LongTensor([self.numy]),\n",
    "                      'y': csr_to_pad_tensor(self.dataset.labels[ids], self.numy),\n",
    "                      'ids': ids,\n",
    "                      'xfts': self.dataset.get_fts(ids)\n",
    "                     }\n",
    "                \n",
    "        return batch_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "f46123c3",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-11-29T22:42:50.644736Z",
     "start_time": "2021-11-29T22:42:50.642137Z"
    }
   },
   "outputs": [],
   "source": [
    "trainloader = torch.utils.data.DataLoader(trainset, batch_size=args.bsz, shuffle=True, num_workers=4)\n",
    "testloader = torch.utils.data.DataLoader(testset, batch_size=args.bsz, shuffle=False, num_workers=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "aefffc22",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-11-29T22:42:51.415502Z",
     "start_time": "2021-11-29T22:42:51.405695Z"
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "class Net(nn.Module):\n",
    "    def __init__(self, encoder, args):\n",
    "        super().__init__()\n",
    "        self.to_patch_embedding = nn.Sequential(\n",
    "            Rearrange('b c (h p1) (w p2) -> b (h w) (p1 p2 c)', p1 = args.patch_height, p2 = args.patch_width),\n",
    "            nn.Linear(args.patch_dim, args.embed_dim),\n",
    "        )\n",
    "        self.encoder = encoder\n",
    "        self.numy = args.numy\n",
    "        self.dropout = nn.Dropout(args.dropout)\n",
    "        if args.per_label_task:\n",
    "            self.w = nn.Sequential(nn.Linear(args.embed_dim, 2*args.embed_dim), \n",
    "                                   nn.ReLU(), \n",
    "                                   nn.Linear(2*args.embed_dim, 1))\n",
    "        else:\n",
    "            self.w = nn.Linear(args.embed_dim, args.numy)\n",
    "        \n",
    "    def get_device(self):\n",
    "        return list(self.parameters())[0].device\n",
    "    \n",
    "    def forward(self, b):\n",
    "        patch_embs = self.to_patch_embedding(b)\n",
    "        seq_len = patch_embs.size(1)\n",
    "        batch_size = patch_embs.size(0)\n",
    "        \n",
    "        pos_ids = torch.arange(seq_len, device=patch_embs.device).view(1, -1)\n",
    "        pos_embs = self.encoder.position_embedding(pos_ids)\n",
    "        embs = patch_embs + pos_embs\n",
    "        \n",
    "        if args.per_token_decoder:\n",
    "            query_embs = self.encoder.query_position_embedding(pos_ids).repeat(batch_size, 1, 1)\n",
    "            query_mask = None\n",
    "        else:\n",
    "            query_embs = self.encoder.query_task_embedding.weight.repeat(batch_size, 1, 1)\n",
    "            query_mask = None\n",
    "            \n",
    "        embs = self.encoder.perceiver(\n",
    "            inputs=embs,\n",
    "            query=query_embs,\n",
    "            input_mask=None,\n",
    "            query_mask=None\n",
    "        )\n",
    "        \n",
    "        if self.encoder.per_token_decoder:\n",
    "            embs = embs.mean(dim=1)\n",
    "        else:\n",
    "            embs = embs.squeeze()\n",
    "    \n",
    "        out = self.w(self.dropout(embs))\n",
    "        return out.squeeze()\n",
    "    \n",
    "class OvABCELoss(nn.Module):\n",
    "    def __init__(self, args, reduction='mean'):\n",
    "        super(OvABCELoss, self).__init__()\n",
    "        if args.loss_with_logits:\n",
    "            self.criterion = torch.nn.BCEWithLogitsLoss(reduction=reduction)\n",
    "        else:\n",
    "            self.criterion = torch.nn.BCELoss(reduction=reduction)\n",
    "\n",
    "    def forward(self, model, b):\n",
    "        out = model(b)\n",
    "        targets = torch.zeros((out.shape[0], out.shape[1]+1), device=out.device).scatter_(1, b['y']['inds'], 1)[:, :-1]\n",
    "        loss = self.criterion(out, targets)\n",
    "        return loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "f6b36845",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-11-29T22:42:52.703954Z",
     "start_time": "2021-11-29T22:42:52.700914Z"
    }
   },
   "outputs": [],
   "source": [
    "net = Net(encoder, args)\n",
    "criterion = nn.CrossEntropyLoss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "820f5a54",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-11-29T22:42:53.720428Z",
     "start_time": "2021-11-29T22:42:53.709134Z"
    }
   },
   "outputs": [],
   "source": [
    "optims = [transformers.optimization.AdamW(net.parameters(), **{'lr': args.lr, 'eps': 1e-06, 'weight_decay': 0.01})]\n",
    "total_steps = len(trainloader)*args.n_epochs\n",
    "schedulers = [transformers.get_linear_schedule_with_warmup(optim, num_warmup_steps=int(args.warmup*total_steps), num_training_steps=total_steps) for optim in optims]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "b84958ae",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-11-29T22:42:57.415602Z",
     "start_time": "2021-11-29T22:42:54.385648Z"
    }
   },
   "outputs": [],
   "source": [
    "net.to(args.device);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "40498200",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-11-30T00:02:16.681070Z",
     "start_time": "2021-11-30T00:02:16.675962Z"
    }
   },
   "outputs": [],
   "source": [
    "def evaluate(net, testloader, epoch=-1):\n",
    "    net.eval()\n",
    "    test_loss = 0\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    t = tqdm(testloader, desc='', leave=True)\n",
    "    with torch.no_grad():\n",
    "        for batch_idx, (inputs, targets) in enumerate(t):\n",
    "            inputs, targets = inputs.to(args.device), targets.to(args.device)\n",
    "            outputs = net(inputs)\n",
    "            loss = criterion(outputs, targets)\n",
    "\n",
    "            test_loss += loss.item()\n",
    "            _, predicted = outputs.max(1)\n",
    "            total += targets.size(0)\n",
    "            correct += predicted.eq(targets).sum().item()\n",
    "\n",
    "            t.set_description(' '.join([str(batch_idx), str(len(testloader)), 'Loss: %.3f | Acc: %.3f%% (%d/%d)'\n",
    "                % (test_loss/(batch_idx+1), 100.*correct/total, correct, total)]))\n",
    "    \n",
    "    acc = 100.*correct/total\n",
    "    loss = test_loss/(batch_idx+1)\n",
    "    return loss, acc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "79193c72",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-11-29T23:45:43.543802Z",
     "start_time": "2021-11-29T22:42:57.417361Z"
    },
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7796ca3e3ea94114baa2ce2eb00357c8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch: 0, Loss: 0.0:   0%|          | 0/3125 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mean loss after epoch 0/10: 1.9841E+00\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "14eda42851ca45c0b9219c863007cf79",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch: 0, Loss: 0.0:   0%|          | 0/3125 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mean loss after epoch 1/10: 1.6608E+00\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d2bef292e5cd4ffd9e4b07a50c84c1ea",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch: 0, Loss: 0.0:   0%|          | 0/3125 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_77306/3082761451.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     12\u001b[0m         \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcriterion\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mout\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mb\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'label'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     13\u001b[0m         \u001b[0mloss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 14\u001b[0;31m         \u001b[0;32mfor\u001b[0m \u001b[0moptim\u001b[0m \u001b[0;32min\u001b[0m \u001b[0moptims\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0moptim\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     15\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0msch\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mschedulers\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0msch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     16\u001b[0m         \u001b[0mcum_loss\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0mloss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitem\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/work2/08343/nilesh/maverick2/anaconda3/envs/xc/lib/python3.7/site-packages/torch/optim/lr_scheduler.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     63\u001b[0m                 \u001b[0minstance\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_step_count\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     64\u001b[0m                 \u001b[0mwrapped\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__get__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minstance\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcls\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 65\u001b[0;31m                 \u001b[0;32mreturn\u001b[0m \u001b[0mwrapped\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     66\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     67\u001b[0m             \u001b[0;31m# Note that the returned function here is no longer a bound method,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/work2/08343/nilesh/maverick2/anaconda3/envs/xc/lib/python3.7/site-packages/torch/optim/optimizer.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     86\u001b[0m                 \u001b[0mprofile_name\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m\"Optimizer.step#{}.step\"\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mobj\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__class__\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__name__\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     87\u001b[0m                 \u001b[0;32mwith\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mautograd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mprofiler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrecord_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mprofile_name\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 88\u001b[0;31m                     \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     89\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mwrapper\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     90\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/work2/08343/nilesh/maverick2/anaconda3/envs/xc/lib/python3.7/site-packages/transformers/optimization.py\u001b[0m in \u001b[0;36mstep\u001b[0;34m(self, closure)\u001b[0m\n\u001b[1;32m    349\u001b[0m                 \u001b[0mexp_avg\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmul_\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbeta1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0madd_\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgrad\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0malpha\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1.0\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mbeta1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    350\u001b[0m                 \u001b[0mexp_avg_sq\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmul_\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbeta2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0maddcmul_\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgrad\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgrad\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1.0\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mbeta2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 351\u001b[0;31m                 \u001b[0mdenom\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mexp_avg_sq\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msqrt\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0madd_\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgroup\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"eps\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    352\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    353\u001b[0m                 \u001b[0mstep_size\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgroup\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"lr\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "best_acc = -100\n",
    "for epoch in range(args.n_epochs):\n",
    "    net.train()\n",
    "    cum_loss = 0; ctr = 0\n",
    "    t = tqdm(trainloader, desc='Epoch: 0, Loss: 0.0', leave=True)\n",
    "          \n",
    "    for b in t:        \n",
    "        for optim in optims: optim.zero_grad()\n",
    "        b = ToD({'input': b[0], 'label': b[1]}, args.device)\n",
    "        with torch.cuda.amp.autocast(enabled=args.amp):\n",
    "            out = net(b['input'])\n",
    "        loss = criterion(out, b['label'])\n",
    "        loss.backward()\n",
    "        for optim in optims: optim.step()\n",
    "        for sch in schedulers: sch.step()\n",
    "        cum_loss += loss.item()\n",
    "        ctr += 1\n",
    "        t.set_description('Epoch: %d/%d, Loss: %.4E'%(epoch, args.n_epochs, (cum_loss/ctr)), refresh=True)\n",
    "    \n",
    "    print(f'mean loss after epoch {epoch}/{args.n_epochs}: {\"%.4E\"%(cum_loss/ctr)}', flush=True)\n",
    "    if epoch%args.eval_interval == 0 or epoch == (args.n_epochs-1):\n",
    "        test_loss, test_acc = evaluate(net, testloader)\n",
    "\n",
    "        if test_acc > best_acc:\n",
    "            best_acc = test_acc\n",
    "            print(f'Found new best model with acc: {\"%.2f\"%best_acc}\\n')\n",
    "            with open(f'{OUT_DIR}/log.txt', 'a') as f:\n",
    "                print(f'epoch: {epoch}, test acc: {test_acc}, train loss: {cum_loss/ctr}, test loss: {test_loss}', file=f)\n",
    "            torch.save(net.state_dict(), f'{OUT_DIR}/model.pt')\n",
    "    sys.stdout.flush()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "714190ee",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-11-30T00:14:08.332576Z",
     "start_time": "2021-11-30T00:05:14.806256Z"
    }
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a8a64a5feb854a94a760d709df989326",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/3125 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "test_loss, test_acc = evaluate(net, trainloader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "d8536a83",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-11-18T21:38:58.932235Z",
     "start_time": "2021-11-18T21:38:58.913729Z"
    }
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'model' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_5437/1918826831.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mnum_params\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0;32mfor\u001b[0m \u001b[0mp\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mparameters\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m     \u001b[0mnum_params\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mprod\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mnum_params\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'model' is not defined"
     ]
    }
   ],
   "source": [
    "num_params = 0\n",
    "for p in model.parameters():\n",
    "    num_params += np.prod(p.shape)\n",
    "\n",
    "num_params"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:vit]",
   "language": "python",
   "name": "conda-env-vit-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
